"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[2916],{8453:(i,n,e)=>{e.d(n,{R:()=>r,x:()=>a});var t=e(6540);const o={},s=t.createContext(o);function r(i){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof i?i(n):{...n,...i}},[n,i])}function a(i){let n;return n=i.disableParentContext?"function"==typeof i.components?i.components(o):i.components||o:r(i.components),t.createElement(s.Provider,{value:n},i.children)}},9796:(i,n,e)=>{e.r(n),e.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"digital-twin/06-unity-visualization","title":"Unity Visualization","description":"Utilizing Unity for high-fidelity visualization and human-robot interaction in digital twins.","source":"@site/docs/digital-twin/06-unity-visualization.md","sourceDirName":"digital-twin","slug":"/digital-twin/06-unity-visualization","permalink":"/-physical-ai-humanoid-robotics-book/docs/digital-twin/06-unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/RajaHadi/-physical-ai-humanoid-robotics-book/tree/main/docs/digital-twin/06-unity-visualization.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"06-unity-visualization","title":"Unity Visualization","sidebar_label":"Unity Visuals","description":"Utilizing Unity for high-fidelity visualization and human-robot interaction in digital twins."},"sidebar":"tutorialSidebar","previous":{"title":"Env & Interaction","permalink":"/-physical-ai-humanoid-robotics-book/docs/digital-twin/05-environment-interaction"},"next":{"title":"Best Practices","permalink":"/-physical-ai-humanoid-robotics-book/docs/digital-twin/07-best-practices"}}');var o=e(4848),s=e(8453);const r={id:"06-unity-visualization",title:"Unity Visualization",sidebar_label:"Unity Visuals",description:"Utilizing Unity for high-fidelity visualization and human-robot interaction in digital twins."},a="Unity Visualization",l={},c=[{value:"The Unity Robotics Hub",id:"the-unity-robotics-hub",level:2},{value:"URDF Import Workflow",id:"urdf-import-workflow",level:2},{value:"Steps:",id:"steps",level:3},{value:"Example: Importing <code>humanoid.urdf</code>",id:"example-importing-humanoidurdf",level:3},{value:"Human-Robot Interaction (HRI) Scenes",id:"human-robot-interaction-hri-scenes",level:2},{value:"Setting Up a Basic Interaction Scene:",id:"setting-up-a-basic-interaction-scene",level:3},{value:"Example: Virtual Joystick Control",id:"example-virtual-joystick-control",level:3}];function d(i){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...i.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"unity-visualization",children:"Unity Visualization"})}),"\n",(0,o.jsx)(n.p,{children:"While Gazebo excels in physics-based simulation, Unity (a powerful real-time 3D development platform) can be leveraged for high-fidelity visualization, advanced rendering, and rich human-robot interaction (HRI) scenarios. It's particularly useful when aesthetics and complex user interfaces are paramount."}),"\n",(0,o.jsx)(n.h2,{id:"the-unity-robotics-hub",children:"The Unity Robotics Hub"}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.strong,{children:"Unity Robotics Hub"})," is a collection of tools, tutorials, and resources that facilitate the integration of Unity with robotics platforms like ROS 2. It provides packages that allow:"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Importing URDF and SDF models directly into Unity."}),"\n",(0,o.jsxs)(n.li,{children:["Communicating with ROS 2 (using ",(0,o.jsx)(n.code,{children:"Unity.Robotics.ROSTCPConnector"}),")."]}),"\n",(0,o.jsx)(n.li,{children:"Developing sophisticated HRI interfaces."}),"\n",(0,o.jsx)(n.li,{children:"Creating custom sensor simulations with Unity's rendering capabilities."}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"urdf-import-workflow",children:"URDF Import Workflow"}),"\n",(0,o.jsx)(n.p,{children:"Bringing your robot model (defined in URDF from Module 1) into Unity is a streamlined process with the Unity Robotics Hub."}),"\n",(0,o.jsx)(n.h3,{id:"steps",children:"Steps:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Install Unity Editor"}),": Ensure you have a compatible version of Unity installed (e.g., via Unity Hub)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Create New Project"}),": Start a new 3D Unity project."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Import Robotics-ROS Package"}),": From the Unity Asset Store or GitHub, import the ",(0,o.jsx)(n.code,{children:"Unity.Robotics.ROSTCPConnector"})," and ",(0,o.jsx)(n.code,{children:"Unity.Robotics.UrdfImporter"})," packages."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Import URDF File"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Go to ",(0,o.jsx)(n.code,{children:"Robotics > URDF Importer > Import URDF from file"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Select your robot's ",(0,o.jsx)(n.code,{children:".urdf"})," file (e.g., ",(0,o.jsx)(n.code,{children:"humanoid.urdf"})," from Module 1)."]}),"\n",(0,o.jsx)(n.li,{children:"The importer will generate a Unity GameObject hierarchy that mirrors your URDF's links and joints."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.h3,{id:"example-importing-humanoidurdf",children:["Example: Importing ",(0,o.jsx)(n.code,{children:"humanoid.urdf"})]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"# Assuming your URDF is at `src/ros2_foundations/urdf/humanoid.urdf`\r\n# In Unity:\r\n# 1. Ensure Unity.Robotics.UrdfImporter is installed.\r\n# 2. Go to 'Robotics' -> 'URDF Importer' -> 'Import URDF from File'.\r\n# 3. Browse to and select your humanoid.urdf.\r\n# 4. Configure import settings (e.g., generate colliders, import textures).\r\n# 5. Click 'Import'.\r\n#\r\n# A new GameObject will be created in your scene, named after your robot,\r\n# containing all the links and joints.\n"})}),"\n",(0,o.jsx)(n.p,{children:"This process automatically handles converting URDF visual and collision geometries into Unity's Mesh Renderers and Colliders, respectively."}),"\n",(0,o.jsx)(n.h2,{id:"human-robot-interaction-hri-scenes",children:"Human-Robot Interaction (HRI) Scenes"}),"\n",(0,o.jsx)(n.p,{children:"Unity's strength in interactive 3D environments makes it ideal for designing and testing HRI scenarios."}),"\n",(0,o.jsx)(n.h3,{id:"setting-up-a-basic-interaction-scene",children:"Setting Up a Basic Interaction Scene:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Import Robot"}),": Follow the URDF import workflow above."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Environment Design"}),": Create a realistic or abstract environment using Unity's built-in tools or imported assets (e.g., rooms, obstacles, interactive objects)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"User Interface (UI)"}),": Design UI elements (buttons, sliders, data displays) to allow human operators to send commands to the robot or visualize its internal state. This can be done using Unity's UI Canvas system."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 Communication"}),": Use the ",(0,o.jsx)(n.code,{children:"Unity.Robotics.ROSTCPConnector"})," to establish communication between your Unity scene and a ROS 2 network.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Publish control commands from Unity UI to ROS 2 topics."}),"\n",(0,o.jsx)(n.li,{children:"Subscribe to robot state (joint angles, sensor data) from ROS 2 topics to update the Unity visualization."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Interactive Elements"}),": Implement scripts (in C#) to enable human interaction with the scene:","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Clicking on objects to pick them up."}),"\n",(0,o.jsx)(n.li,{children:"Dragging robot end-effectors to guide movement."}),"\n",(0,o.jsx)(n.li,{children:"Visualizing robot's perception data (e.g., LiDAR point clouds, camera feeds)."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"example-virtual-joystick-control",children:"Example: Virtual Joystick Control"}),"\n",(0,o.jsxs)(n.p,{children:["You could create a simple UI joystick in Unity that publishes velocity commands to a ",(0,o.jsx)(n.code,{children:"/cmd_vel"})," ROS 2 topic, which your robot's control node (from Module 1) then subscribes to. This provides an intuitive way for a human to teleoperate the virtual robot."]})]})}function h(i={}){const{wrapper:n}={...(0,s.R)(),...i.components};return n?(0,o.jsx)(n,{...i,children:(0,o.jsx)(d,{...i})}):d(i)}}}]);