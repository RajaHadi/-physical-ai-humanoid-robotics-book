"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[1681],{5327:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"digital-twin/03-sensor-simulation","title":"Sensors in Simulation","description":"Modeling LiDAR, Depth Cameras, RGB cameras, and IMUs in simulated environments.","source":"@site/docs/digital-twin/03-sensor-simulation.md","sourceDirName":"digital-twin","slug":"/digital-twin/03-sensor-simulation","permalink":"/-physical-ai-humanoid-robotics-book/docs/digital-twin/03-sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/RajaHadi/-physical-ai-humanoid-robotics-book/tree/main/docs/digital-twin/03-sensor-simulation.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"id":"03-sensor-simulation","title":"Sensors in Simulation","sidebar_label":"Sensor Simulation","description":"Modeling LiDAR, Depth Cameras, RGB cameras, and IMUs in simulated environments."},"sidebar":"tutorialSidebar","previous":{"title":"Physics Basics","permalink":"/-physical-ai-humanoid-robotics-book/docs/digital-twin/02-physics-basics"},"next":{"title":"Humanoid Models","permalink":"/-physical-ai-humanoid-robotics-book/docs/digital-twin/04-humanoid-modeling"}}');var r=a(4848),s=a(8453);const t={id:"03-sensor-simulation",title:"Sensors in Simulation",sidebar_label:"Sensor Simulation",description:"Modeling LiDAR, Depth Cameras, RGB cameras, and IMUs in simulated environments."},o="Sensors in Simulation",l={},d=[{value:"Sensor Noise Models",id:"sensor-noise-models",level:2},{value:"LiDAR Configuration (SDF Example)",id:"lidar-configuration-sdf-example",level:2},{value:"Camera Configuration (SDF Example)",id:"camera-configuration-sdf-example",level:2},{value:"RGB Camera",id:"rgb-camera",level:3},{value:"Depth Camera",id:"depth-camera",level:3},{value:"IMU (Inertial Measurement Unit) Configuration (SDF Example)",id:"imu-inertial-measurement-unit-configuration-sdf-example",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"sensors-in-simulation",children:"Sensors in Simulation"})}),"\n",(0,r.jsx)(n.p,{children:"Robot perception relies heavily on sensor data. In a digital twin, accurately simulating these sensors is crucial for developing robust control systems and perception algorithms that can later be transferred to real robots. This involves not only replicating the sensor's output but also modeling its physical properties and noise characteristics."}),"\n",(0,r.jsx)(n.h2,{id:"sensor-noise-models",children:"Sensor Noise Models"}),"\n",(0,r.jsxs)(n.p,{children:["As discussed in the glossary, ",(0,r.jsx)(n.strong,{children:"Sensor Noise Models"}),' are critical for making simulated data realistic. Without noise, an AI agent might learn patterns that don\'t exist in the real world, leading to a significant "sim-to-real" gap. Common noise types include:']}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Gaussian Noise"}),": Random fluctuations following a normal distribution."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Drift"}),": A gradual change in sensor bias over time."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Outliers"}),": Sporadic, erroneous readings."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"lidar-configuration-sdf-example",children:"LiDAR Configuration (SDF Example)"}),"\n",(0,r.jsx)(n.p,{children:"LiDAR (Light Detection and Ranging) sensors measure distances by emitting laser pulses. They are fundamental for mapping and navigation."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<sensor name="lidar" type="ray">\r\n  <pose>0 0 0.1 0 0 0</pose> \x3c!-- Relative to its parent link --\x3e\r\n  <ray>\r\n    <scan>\r\n      <horizontal>\r\n        <samples>640</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>-2.2</min_angle>\r\n        <max_angle>2.2</max_angle>\r\n      </horizontal>\r\n      <vertical>\r\n        <samples>1</samples>\r\n        <resolution>1</resolution>\r\n        <min_angle>0</min_angle>\r\n        <max_angle>0</max_angle>\r\n      </vertical>\r\n    </scan>\r\n    <range>\r\n      <min>0.08</min>\r\n      <max>10.0</max>\r\n      <resolution>0.01</resolution>\r\n    </range>\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.01</stddev> \x3c!-- Standard deviation of the Gaussian noise --\x3e\r\n    </noise>\r\n  </ray>\r\n  <always_on>1</always_on>\r\n  <update_rate>10</update_rate> \x3c!-- 10 Hz update rate --\x3e\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(n.p,{children:"This SDF snippet defines a horizontal LiDAR with 640 samples over a 4.4 radian field of view, a range of 0.08m to 10m, and a Gaussian noise model."}),"\n",(0,r.jsx)(n.h2,{id:"camera-configuration-sdf-example",children:"Camera Configuration (SDF Example)"}),"\n",(0,r.jsx)(n.p,{children:"Cameras provide rich visual information about the environment. RGB cameras capture color images, while depth cameras also provide distance information for each pixel."}),"\n",(0,r.jsx)(n.h3,{id:"rgb-camera",children:"RGB Camera"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<sensor name="camera" type="camera">\r\n  <pose>0.05 0 0.05 0 0 0</pose>\r\n  <camera>\r\n    <horizontal_fov>1.047</horizontal_fov> \x3c!-- 60 degrees --\x3e\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n      <format>R8G8B8</format>\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>100</far>\r\n    </clip>\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.007</stddev>\r\n    </noise>\r\n  </camera>\r\n  <always_on>1</always_on>\r\n  <update_rate>30</update_rate>\r\n  <visualize>true</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(n.h3,{id:"depth-camera",children:"Depth Camera"}),"\n",(0,r.jsx)(n.p,{children:"Depth cameras are crucial for 3D perception, allowing robots to understand the geometry of their surroundings."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<sensor name="depth_camera" type="depth">\r\n  <pose>0.05 0 0.05 0 0 0</pose>\r\n  <camera>\r\n    <horizontal_fov>1.047</horizontal_fov>\r\n    <image>\r\n      <width>640</width>\r\n      <height>480</height>\r\n      <format>L_DEPTH</format> \x3c!-- Format for depth data --\x3e\r\n    </image>\r\n    <clip>\r\n      <near>0.1</near>\r\n      <far>10</far>\r\n    </clip>\r\n    <noise>\r\n      <type>gaussian</type>\r\n      <mean>0.0</mean>\r\n      <stddev>0.02</stddev>\r\n    </noise>\r\n  </camera>\r\n  <always_on>1</always_on>\r\n  <update_rate>30</update_rate>\r\n  <visualize>false</visualize>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(n.h2,{id:"imu-inertial-measurement-unit-configuration-sdf-example",children:"IMU (Inertial Measurement Unit) Configuration (SDF Example)"}),"\n",(0,r.jsx)(n.p,{children:"IMUs measure linear acceleration and angular velocity, providing essential data for robot localization and state estimation."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\r\n  <pose>0 0 0 0 0 0</pose>\r\n  <imu>\r\n    <angular_velocity>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.0002</stddev>\r\n          <bias_mean>0.0000075</bias_mean>\r\n          <bias_stddev>0.0000008</bias_stddev>\r\n        </noise>\r\n      </x>\r\n      \x3c!-- y and z angular velocity noise similarly configured --\x3e\r\n    </angular_velocity>\r\n    <linear_acceleration>\r\n      <x>\r\n        <noise type="gaussian">\r\n          <mean>0.0</mean>\r\n          <stddev>0.017</stddev>\r\n          <bias_mean>0.1</bias_mean>\r\n          <bias_stddev>0.001</bias_stddev>\r\n        </noise>\r\n      </x>\r\n      \x3c!-- y and z linear acceleration noise similarly configured --\x3e\r\n    </linear_acceleration>\r\n  </imu>\r\n  <always_on>1</always_on>\r\n  <update_rate>100</update_rate>\r\n</sensor>\n'})}),"\n",(0,r.jsx)(n.p,{children:"IMU noise models can be quite complex, including terms for random walk, bias, and temperature effects. This example shows a basic Gaussian noise with bias for angular velocity and linear acceleration."})]})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>t,x:()=>o});var i=a(6540);const r={},s=i.createContext(r);function t(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);