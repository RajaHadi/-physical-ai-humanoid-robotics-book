"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[871],{1308:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"vla/ros2-action-generation","title":"05 - ROS 2 Action Generation for VLA","description":"This chapter focuses on the Action component of Vision-Language-Action (VLA) systems, detailing how Large Language Models (LLMs) translate cognitive plans into executable robotic behaviors using the ROS 2 Action interface. We cover both standard ROS 2 actions (Nav2, MoveIt) and custom action definitions for complex VLA tasks.","source":"@site/docs/vla/05-ros2-action-generation.md","sourceDirName":"vla","slug":"/vla/ros2-action-generation","permalink":"/-physical-ai-humanoid-robotics-book/docs/vla/ros2-action-generation","draft":false,"unlisted":false,"editUrl":"https://github.com/RajaHadi/-physical-ai-humanoid-robotics-book/tree/main/docs/vla/05-ros2-action-generation.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"04 - Vision and Depth Perception for VLA","permalink":"/-physical-ai-humanoid-robotics-book/docs/vla/vision-perception"},"next":{"title":"06 - Integrated Pipeline Examples","permalink":"/-physical-ai-humanoid-robotics-book/docs/vla/integrated-pipeline-examples"}}');var s=i(4848),t=i(8453);const r={},c="05 - ROS 2 Action Generation for VLA",a={},l=[{value:"5.1 The Role of Actions in ROS 2 Robotics",id:"51-the-role-of-actions-in-ros-2-robotics",level:2},{value:"5.2 Standard ROS 2 Actions: Building Blocks for VLA",id:"52-standard-ros-2-actions-building-blocks-for-vla",level:2},{value:"5.3 Custom ROS 2 Action Definitions for VLA Tasks",id:"53-custom-ros-2-action-definitions-for-vla-tasks",level:2},{value:"5.4 From LLM Plan to ROS 2 Actions",id:"54-from-llm-plan-to-ros-2-actions",level:2},{value:"5.5 Examples of ROS 2 Action Flows for VLA",id:"55-examples-of-ros-2-action-flows-for-vla",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"05---ros-2-action-generation-for-vla",children:"05 - ROS 2 Action Generation for VLA"})}),"\n",(0,s.jsx)(e.p,{children:"This chapter focuses on the Action component of Vision-Language-Action (VLA) systems, detailing how Large Language Models (LLMs) translate cognitive plans into executable robotic behaviors using the ROS 2 Action interface. We cover both standard ROS 2 actions (Nav2, MoveIt) and custom action definitions for complex VLA tasks."}),"\n",(0,s.jsx)(e.h2,{id:"51-the-role-of-actions-in-ros-2-robotics",children:"5.1 The Role of Actions in ROS 2 Robotics"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Communication Primitives"}),": Actions are used for long-running, goal-oriented tasks with continuous feedback and preemptability. Topics handle continuous data, services manage immediate request/response."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Why Actions for VLA?"}),": Actions are ideal for VLA due to:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Goal Management"}),': Sending high-level commands (e.g., "Navigate to kitchen").']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Continuous Feedback"}),': Monitoring robot progress (e.g., "Robot is moving," "Object detected").']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Preemptability"}),": LLM can cancel/modify tasks if new info or plan changes arise."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Structured Results"}),": Clear task outcome (success/failure)."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"52-standard-ros-2-actions-building-blocks-for-vla",children:"5.2 Standard ROS 2 Actions: Building Blocks for VLA"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Decision"}),": Explain ",(0,s.jsx)(e.strong,{children:"standard MoveIt/Nav2 actions as fundamental building blocks"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Nav2 Actions (Navigation)"}),":","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"NavigateToPose"}),": Commands robot to a specific 2D pose. LLM plans often translate into sequences of these."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"ComputePathToPose"}),": Plans a path without immediate execution, allowing LLM inspection."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"MoveIt 2 Actions (Manipulation)"}),":","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"MoveGroup"}),": Controls manipulators for motion planning, collision avoidance, and trajectory execution."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"FollowJointTrajectory"}),": Executes pre-defined joint trajectories."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Integration in VLA"}),": LLM-generated plans decompose into these standard actions, called by a high-level executive."]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"53-custom-ros-2-action-definitions-for-vla-tasks",children:"5.3 Custom ROS 2 Action Definitions for VLA Tasks"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Decision"}),": Explain ",(0,s.jsx)(e.strong,{children:"custom ROS 2 action definitions for encapsulating higher-level, application-specific VLA tasks"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Purpose"}),": Custom actions define unique robotic behaviors, abstracting multiple standard actions into a single high-level interface for the LLM planner's output."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"When to Create Custom Actions"}),': For tasks combining multiple standard actions with specific logic (e.g., "PickUpObject" involves navigation, perception, arm movement, grasping).']}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Defining a Custom Action (Conceptual)"}),":","\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"# vla_msgs/action/PickUpObject.action\r\n# Goal: string object_id, geometry_msgs/Pose object_pose\r\n# ---\r\n# Result: bool success, string message\r\n# ---\r\n# Feedback: float32 progress_percentage, string current_sub_task\n"})}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Implementing a Custom Action Server"}),": A ROS 2 node implements the custom action logic, typically calling clients for standard Nav2/MoveIt actions."]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"54-from-llm-plan-to-ros-2-actions",children:"5.4 From LLM Plan to ROS 2 Actions"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"The Action Graph"}),": LLM generates an Action Graph (",(0,s.jsx)(e.code,{children:"data-model.md"}),", ",(0,s.jsx)(e.code,{children:"contracts/interfaces.md"}),") representing the VLA task."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Action Execution Engine"}),": A high-level ROS 2 node interprets this Action Graph, acting as an action client for standard and custom actions."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Mapping"}),": Maps abstract plan steps to ROS 2 action calls, providing parameters from the plan and perception data."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Feedback Loop"}),": Engine provides feedback to the LLM planner for plan adjustments or re-planning."]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"55-examples-of-ros-2-action-flows-for-vla",children:"5.5 Examples of ROS 2 Action Flows for VLA"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:'"Pick up the red cup"'}),": LLM plans ",(0,s.jsx)(e.code,{children:"NavigateTo(red_cup_location)"})," and ",(0,s.jsx)(e.code,{children:"PickUpObject(red_cup_id, red_cup_pose)"}),". Executive calls these, with ",(0,s.jsx)(e.code,{children:"PickUpObject"})," internally using MoveIt."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:'"Clean the room"'}),": LLM orchestrates ",(0,s.jsx)(e.code,{children:"ExploreRoom"}),", then iteratively calls ",(0,s.jsx)(e.code,{children:"PickUpObject"}),", ",(0,s.jsx)(e.code,{children:"NavigateToPose"}),", ",(0,s.jsx)(e.code,{children:"PlaceObject"})," for each item."]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>c});var o=i(6540);const s={},t=o.createContext(s);function r(n){const e=o.useContext(t);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function c(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),o.createElement(t.Provider,{value:e},n.children)}}}]);