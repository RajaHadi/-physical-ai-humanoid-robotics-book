<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-vla/foundations-vla" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">01 - Foundations of Vision-Language-Action (VLA) | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="01 - Foundations of Vision-Language-Action (VLA) | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="This chapter introduces Vision-Language-Action (VLA) systems for humanoid robots, exploring the motivation for integrating vision, language, and action to enable intelligent human-robot interaction. It covers the high-level architecture of a complete VLA pipeline, setting the stage for subsequent detailed discussions."><meta data-rh="true" property="og:description" content="This chapter introduces Vision-Language-Action (VLA) systems for humanoid robots, exploring the motivation for integrating vision, language, and action to enable intelligent human-robot interaction. It covers the high-level architecture of a complete VLA pipeline, setting the stage for subsequent detailed discussions."><link data-rh="true" rel="icon" href="/-physical-ai-humanoid-robotics-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla"><link data-rh="true" rel="alternate" href="https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla" hreflang="en"><link data-rh="true" rel="alternate" href="https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"01 - Foundations of Vision-Language-Action (VLA)","item":"https://rajahadi.github.io/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla"}]}</script><link rel="alternate" type="application/rss+xml" href="/-physical-ai-humanoid-robotics-book/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/-physical-ai-humanoid-robotics-book/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed"><link rel="stylesheet" href="/-physical-ai-humanoid-robotics-book/assets/css/styles.0b570e11.css">
<script src="/-physical-ai-humanoid-robotics-book/assets/js/runtime~main.03dcb68e.js" defer="defer"></script>
<script src="/-physical-ai-humanoid-robotics-book/assets/js/main.5bbffdfc.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/-physical-ai-humanoid-robotics-book/img/hero-ai.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top navbar--primary"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/-physical-ai-humanoid-robotics-book/"><div class="navbar__logo"><img src="/-physical-ai-humanoid-robotics-book/img/hero-ai.png" alt="Physical AI &amp; Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/-physical-ai-humanoid-robotics-book/img/hero-ai.png" alt="Physical AI &amp; Humanoid Robotics Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/-physical-ai-humanoid-robotics-book/docs/ros2/01-introduction">Modules</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/RajaHadi/-physical-ai-humanoid-robotics-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/-physical-ai-humanoid-robotics-book/docs/ros2/01-introduction"><span title="ROS 2 Foundations" class="categoryLinkLabel_W154">ROS 2 Foundations</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/-physical-ai-humanoid-robotics-book/docs/digital-twin/01-intro-digital-twins"><span title="Digital Twin" class="categoryLinkLabel_W154">Digital Twin</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/-physical-ai-humanoid-robotics-book/docs/isaac-sim/introduction"><span title="NVIDIA Isaac Sim" class="categoryLinkLabel_W154">NVIDIA Isaac Sim</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla"><span title="VLA Robotics LLM" class="categoryLinkLabel_W154">VLA Robotics LLM</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla"><span title="01 - Foundations of Vision-Language-Action (VLA)" class="linkLabel_WmDU">01 - Foundations of Vision-Language-Action (VLA)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/whisper-language"><span title="02 - Whisper + Language Understanding" class="linkLabel_WmDU">02 - Whisper + Language Understanding</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/cognitive-planning"><span title="03 - Cognitive Planning with Large Language Models (LLMs)" class="linkLabel_WmDU">03 - Cognitive Planning with Large Language Models (LLMs)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/vision-perception"><span title="04 - Vision and Depth Perception for VLA" class="linkLabel_WmDU">04 - Vision and Depth Perception for VLA</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/ros2-action-generation"><span title="05 - ROS 2 Action Generation for VLA" class="linkLabel_WmDU">05 - ROS 2 Action Generation for VLA</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/integrated-pipeline-examples"><span title="06 - Integrated Pipeline Examples" class="linkLabel_WmDU">06 - Integrated Pipeline Examples</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/-physical-ai-humanoid-robotics-book/docs/vla/capstone-preparation"><span title="07 - Capstone Preparation: &quot;The Autonomous Humanoid&quot;" class="linkLabel_WmDU">07 - Capstone Preparation: &quot;The Autonomous Humanoid&quot;</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/-physical-ai-humanoid-robotics-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">VLA Robotics LLM</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">01 - Foundations of Vision-Language-Action (VLA)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>01 - Foundations of Vision-Language-Action (VLA)</h1></header>
<p>This chapter introduces Vision-Language-Action (VLA) systems for humanoid robots, exploring the motivation for integrating vision, language, and action to enable intelligent human-robot interaction. It covers the high-level architecture of a complete VLA pipeline, setting the stage for subsequent detailed discussions.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="11-introduction-to-embodied-intelligence">1.1 Introduction to Embodied Intelligence<a href="#11-introduction-to-embodied-intelligence" class="hash-link" aria-label="Direct link to 1.1 Introduction to Embodied Intelligence" title="Direct link to 1.1 Introduction to Embodied Intelligence" translate="no">​</a></h2>
<ul>
<li class=""><strong>Embodied Intelligence</strong>: Intelligence demonstrated by an agent situated in and interacting with a physical environment, where cognitive processes are intertwined with physical body, sensory experiences, and motor actions. Unlike disembodied AI, embodied AI learns and reasons through direct physical engagement.</li>
<li class=""><strong>The Need for VLA</strong>: For autonomous humanoid robots in human-centric environments, seamless understanding of natural language, perception of surroundings, and execution of physical actions are crucial. VLA systems bridge human intent (language) and robotic execution (action), using vision for grounding in reality.</li>
<li class=""><strong>Challenges in Humanoid Robotics</strong>: Humanoids face challenges due to complex kinematics, high degrees of freedom, and operating safely in dynamic environments. VLA offers a paradigm for flexible and adaptive behaviors to address these.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="12-high-level-architecture-of-a-vla-pipeline">1.2 High-Level Architecture of a VLA Pipeline<a href="#12-high-level-architecture-of-a-vla-pipeline" class="hash-link" aria-label="Direct link to 1.2 High-Level Architecture of a VLA Pipeline" title="Direct link to 1.2 High-Level Architecture of a VLA Pipeline" translate="no">​</a></h2>
<p>A typical VLA pipeline translates human intent into robotic action through interconnected modules:</p>
<ul>
<li class=""><strong>Microphone</strong>: Captures spoken natural language commands.</li>
<li class=""><strong>Whisper (Speech-to-Text)</strong>: Transcribes audio into text for language understanding.</li>
<li class=""><strong>LLM Planner (Cognitive Planning)</strong>: Interprets text and environmental understanding (from perception) to generate a structured sequence of executable robotic actions, often hierarchically.</li>
<li class=""><strong>ROS 2 Action Graph</strong>: Structured representation of planned actions, defining order, parameters, and dependencies.</li>
<li class=""><strong>Navigation + Perception</strong>: Robotic modules manage movement to target locations. Perception continuously processes sensory data (e.g., camera, depth, LiDAR) to understand surroundings, identify objects, and update the robot&#x27;s world model, feeding crucial feedback for grounding and re-planning.</li>
<li class=""><strong>Manipulation</strong>: Upon reaching a target and perceiving objects, the manipulation system (e.g., robotic arms, grippers) executes fine-motor skills (grasping, placing) as specified by the plan.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="13-key-components-and-their-interactions">1.3 Key Components and Their Interactions<a href="#13-key-components-and-their-interactions" class="hash-link" aria-label="Direct link to 1.3 Key Components and Their Interactions" title="Direct link to 1.3 Key Components and Their Interactions" translate="no">​</a></h2>
<p>VLA pipelines integrate traditionally separate AI and robotics domains:</p>
<ul>
<li class=""><strong>Vision</strong>: Robots &quot;see&quot; and interpret the environment via sensor data (RGB, depth, point clouds) for object recognition, 3D pose, and spatial awareness (SLAM). Vision provides physical context.</li>
<li class=""><strong>Language</strong>: Robots &quot;understand&quot; and &quot;reason&quot; with human instructions through speech recognition (Whisper), natural language understanding (NLU) for intent extraction, and LLMs for processing complex commands.</li>
<li class=""><strong>Action</strong>: Robots execute physical tasks, including high-level planning (LLM), mid-level task sequencing (ROS 2 action graphs), and low-level control (Nav2, MoveIt). Actions are grounded in reality via visual feedback.</li>
<li class=""><strong>Feedback Loops</strong>: Continuous feedback from vision and action execution updates the LLM&#x27;s understanding and robot&#x27;s state, enabling adaptive and robust behavior.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="14-benefits-of-vla-for-humanoid-robots">1.4 Benefits of VLA for Humanoid Robots<a href="#14-benefits-of-vla-for-humanoid-robots" class="hash-link" aria-label="Direct link to 1.4 Benefits of VLA for Humanoid Robots" title="Direct link to 1.4 Benefits of VLA for Humanoid Robots" translate="no">​</a></h2>
<p>VLA systems offer transformative benefits:</p>
<ul>
<li class=""><strong>Natural Interaction</strong>: Intuitive human-robot communication using everyday language.</li>
<li class=""><strong>Complex Commands</strong>: LLMs enable robots to interpret and break down abstract instructions (e.g., &quot;Clean the room&quot;) into actionable steps.</li>
<li class=""><strong>Autonomy &amp; Adaptability</strong>: Real-time perception and language understanding allow robots to adapt to unforeseen changes and re-plan.</li>
<li class=""><strong>Cognitive Tasks</strong>: Empowers robots for higher-level reasoning, problem-solving, and decision-making.</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="15-module-overview-and-capstone-preparation">1.5 Module Overview and Capstone Preparation<a href="#15-module-overview-and-capstone-preparation" class="hash-link" aria-label="Direct link to 1.5 Module Overview and Capstone Preparation" title="Direct link to 1.5 Module Overview and Capstone Preparation" translate="no">​</a></h2>
<p>Module 4 provides a comprehensive understanding of VLA systems, from foundational concepts to practical examples. Each chapter details a specific VLA pipeline component. This module prepares learners for the Capstone project, <strong>&quot;The Autonomous Humanoid&quot;</strong>, applying VLA principles to enable humanoid robots to complete complex tasks via voice commands, integrating perception, planning, navigation, and manipulation.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/RajaHadi/-physical-ai-humanoid-robotics-book/tree/main/docs/vla/01-foundations-vla.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/-physical-ai-humanoid-robotics-book/docs/isaac-sim/preparing-module4"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">08 - Preparing for Module 4 (Vision-Language-Action)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/-physical-ai-humanoid-robotics-book/docs/vla/whisper-language"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">02 - Whisper + Language Understanding</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#11-introduction-to-embodied-intelligence" class="table-of-contents__link toc-highlight">1.1 Introduction to Embodied Intelligence</a></li><li><a href="#12-high-level-architecture-of-a-vla-pipeline" class="table-of-contents__link toc-highlight">1.2 High-Level Architecture of a VLA Pipeline</a></li><li><a href="#13-key-components-and-their-interactions" class="table-of-contents__link toc-highlight">1.3 Key Components and Their Interactions</a></li><li><a href="#14-benefits-of-vla-for-humanoid-robots" class="table-of-contents__link toc-highlight">1.4 Benefits of VLA for Humanoid Robots</a></li><li><a href="#15-module-overview-and-capstone-preparation" class="table-of-contents__link toc-highlight">1.5 Module Overview and Capstone Preparation</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Modules</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/-physical-ai-humanoid-robotics-book/docs/ros2/01-introduction">ROS 2 Foundations</a></li><li class="footer__item"><a class="footer__link-item" href="/-physical-ai-humanoid-robotics-book/docs/digital-twin/01-intro-digital-twins">The Digital Twin</a></li><li class="footer__item"><a class="footer__link-item" href="/-physical-ai-humanoid-robotics-book/docs/isaac-sim/introduction">NVIDIA Isaac Sim</a></li><li class="footer__item"><a class="footer__link-item" href="/-physical-ai-humanoid-robotics-book/docs/vla/foundations-vla">VLA Robotics LLM</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/RajaHadi/-physical-ai-humanoid-robotics-book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>